#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Environment Wrapper for Binary Code Perturbation
äºŒè¿›åˆ¶ä»£ç å˜å¼‚ç¯å¢ƒåŒ…è£…å™¨ï¼ˆPython 3ï¼‰

åŠŸèƒ½ï¼š
- è°ƒç”¨ uroboros (Python 2) è¿›è¡Œä»£ç å˜å¼‚
- ä½¿ç”¨ run_utils (Python 3) è¿›è¡Œç›¸ä¼¼åº¦è¯„ä¼°
- æä¾›æ ‡å‡† RL ç¯å¢ƒæ¥å£
"""

import sys
import os
import json
import time
import subprocess
import numpy as np
import pickle
import hashlib
from loguru import logger
import random

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥ç°æœ‰æ¨¡å—
from run_utils import run_one
import run_objdump
from rl_framework.utils.acfg.r2_acfg_features import RadareACFGExtractor

class BinaryPerturbationEnv:
    """
    äºŒè¿›åˆ¶ä»£ç å˜å¼‚ç¯å¢ƒ (Python 3)
    
    ä¸ PPO Agent åœ¨åŒä¸€è¿›ç¨‹ä¸­è¿è¡Œï¼Œé€šè¿‡å‡½æ•°è°ƒç”¨é€šä¿¡
    """
    
    def __init__(
        self,
        save_path,
        dataset_path,
        sample_hold_interval=3,
        max_steps=30,
        output_dir=None,
        detection_method="asm2vec",
        safe_checkpoint_dir=None,
        safe_i2v_dir=None,
        safe_use_gpu=False,
        safe_cache_enabled=False,
        jtrans_model_dir=None,
        jtrans_tokenizer_dir=None,
        jtrans_use_gpu=False,
        feature_mode="full",
        seed=None,
        adaptive_hold=True,
        hold_min=None,
        hold_max=None,
        stall_limit=6,
        progress_eps=1e-4,
        progress_reward_eps=1e-3,
        include_schedule_feature=False,
        strict_invalid_loc=True,
    ):
        """
        å‚æ•°:
            original_binary: åŸå§‹äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            function_name: ç›®æ ‡å‡½æ•°å
            save_path: ä¿å­˜å˜å¼‚ç»“æœçš„è·¯å¾„
        """
        self.save_path = os.path.abspath(save_path)
        # é¡¹ç›®æ ¹ç›®å½•ï¼ˆuroboros æ‰€åœ¨ç›®å½•ï¼‰
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        # ç”¨äºå­˜å‚¨å½“å‰äºŒè¿›åˆ¶æ–‡ä»¶çš„ Top-K å…³é”®å—åœ°å€åˆ—è¡¨
        # æ ¼å¼: [0x401000, 0x401050, 0x401090]
        self.current_critical_blocks = []
        # å½“å‰å‡½æ•°çš„æ‰€æœ‰åŸºæœ¬å—åœ°å€ï¼ˆç”¨äºéšæœºé€‰éTopå—ï¼‰
        self.current_all_blocks = []
        # åŠ è½½æ•°æ®é›†
        if not os.path.exists(dataset_path):
            raise FileNotFoundError(f"Dataset not found: {dataset_path}")
            
        with open(dataset_path, 'r') as f:
            self.dataset = json.load(f)
        
        logger.info(f"å·²åŠ è½½æ•°æ®é›†: {len(self.dataset)} ä¸ªæ ·æœ¬")
        
        # åˆ‡æ¢ç­–ç•¥æ§åˆ¶
        self.sample_hold_interval = sample_hold_interval
        self.adaptive_hold = adaptive_hold
        self.hold_max = int(hold_max) if hold_max is not None else int(sample_hold_interval)
        if hold_min is None:
            self.hold_min = max(1, int(round(self.hold_max * 0.4)))
        else:
            self.hold_min = int(hold_min)
        self.hold_min = max(1, min(self.hold_min, self.hold_max))
        self.stall_limit = int(stall_limit)
        self.progress_eps = float(progress_eps)
        self.progress_reward_eps = float(progress_reward_eps)
        self.include_schedule_feature = bool(include_schedule_feature)
        self.strict_invalid_loc = bool(strict_invalid_loc)
        self.current_hold_limit = self.hold_max
        self.episodes_on_current = 0
        self.current_sample_data = None # å­˜å‚¨å½“å‰æ ·æœ¬çš„å…ƒæ•°æ®
        
        # å½“å‰ç¯å¢ƒçŠ¶æ€å˜é‡
        self.original_binary = None # åŸå§‹äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
        self.function_name = None # ç›®æ ‡å‡½æ•°å
        self.current_binary = None # å½“å‰å˜å¼‚åçš„äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
        self.original_func_addr = None
        
        # ä¸å†éœ€è¦åŠ è½½æ¨¡å‹ï¼ˆé»˜è®¤ä½¿ç”¨ asm2vec æ–¹æ³•ï¼‰
        self.model_original = None
        self.detection_method = detection_method
        
        self.safe_checkpoint_dir = safe_checkpoint_dir
        self.safe_i2v_dir = safe_i2v_dir
        self.safe_use_gpu = safe_use_gpu
        self.safe_cache_enabled = bool(safe_cache_enabled)
        self.safe_cache = {} if self.safe_cache_enabled else None

        self.jtrans_model_dir = jtrans_model_dir
        self.jtrans_tokenizer_dir = jtrans_tokenizer_dir
        self.jtrans_use_gpu = jtrans_use_gpu
        self._jtrans_cache = {}
        self.feature_mode = feature_mode
        self.seed = seed
        if seed is not None:
            random.seed(seed)
            np.random.seed(seed)
        logger.info(f"Using {self.detection_method} detection method")
        
        # å˜å¼‚å†å²
        self.mutation_history = []
        self.step_count = 0
        self.max_steps = max_steps
        self.target_score = 0.40
        self.state_dim = 256  # é»˜è®¤çŠ¶æ€ç»´åº¦ï¼ˆ256ç»´ï¼‰ï¼Œå¯ä»¥é€šè¿‡å‚æ•°ä¿®æ”¹
        # åŠ¨ä½œç©ºé—´ï¼ˆå¿…é¡»ä¸ PPOAgent çš„ action_map ä¿æŒä¸€è‡´ï¼‰
        # å·²æ¥å…¥æ–°åŠ¨ä½œ: 13/14/15/16
        self.all_action_ids = [1, 2, 4, 7, 8, 9, 11, 13, 14, 15, 16]
        self.action_ids = list(self.all_action_ids)
        self.action_id_to_index = {aid: idx for idx, aid in enumerate(self.action_ids)}
        # å›ºå®šå†å²ç‰¹å¾ç»´åº¦ï¼šä¿æŒ 7 binsï¼Œé¿å…æ”¹å˜ 16 ç»´å†å²ç‰¹å¾å¸ƒå±€ï¼ˆå½±å“å·²å®ç°ç½‘ç»œåˆ‡ç‰‡ï¼‰ã€‚
        # æ–°åŠ¨ä½œ 13/14/15/16 ä¼šå‚ä¸ç­–ç•¥å†³ç­–ä¸æ‰§è¡Œï¼Œä½†ä¸è¿›å…¥å†å²ç›´æ–¹å›¾ç»Ÿè®¡ã€‚
        self.hist_action_ids = [1, 2, 4, 7, 8, 9, 11]
        self.hist_action_id_to_index = {aid: idx for idx, aid in enumerate(self.hist_action_ids)}
        self.hist_action_dim = len(self.hist_action_ids)
        self.n_actions = len(self.action_ids)
        # å¥–åŠ±å¡‘å½¢è¶…å‚ï¼šæ˜¾å¼æƒ©ç½šâ€œæ— å˜åŒ–/æ— æ•ˆä½ç½®â€
        self.no_change_eps = 1e-4
        self.no_change_penalty = 0.1
        self.invalid_loc_penalty = 0.5
        # åˆ†æ®µæƒ©ç½šå‚æ•°ï¼ˆæŒ‰â€œè¿ç»­æ¬¡æ•° + è®­ç»ƒé˜¶æ®µâ€è°ƒæ•´ï¼‰
        self.no_change_penalty_factors = (0.6, 1.0, 1.6, 2.2)   # 1, 2~3, 4~6, >=7
        self.invalid_loc_penalty_factors = (1.0, 1.5, 2.2)      # 1, 2~3, >=4
        self.time_penalty_schedule = (0.02, 0.05, 0.08)         # early, mid, late
        self.penalty_cap = 2.5
        # è¿ç»­å¤±è´¥è®¡æ•°ï¼ˆç”¨äºåˆ†æ®µæƒ©ç½šï¼‰
        self.no_change_streak = 0
        self.invalid_loc_streak = 0
        # åˆ†æ•°é™å¹…å¥–åŠ±ï¼ˆè¶Šé™è¶Šå¤šï¼‰
        self.drop_bonus_scale = 3.0
        self.drop_bonus_cap = 2.0
        # ä»»ä½•æœ‰æ•ˆå˜å¼‚ï¼ˆåˆ†æ•°ä¸‹é™ï¼‰ç»™äºˆå°æ­£å¥–ï¼Œé¿å…é•¿æœŸè´Ÿåé¦ˆ
        self.effective_mutation_bonus = 0.2
        # å¥–åŠ±å°ºåº¦ï¼ˆæ›´å‡è¡¡ï¼Œé¿å…åªé ç»ˆæå¥–åŠ±ï¼‰
        self.incremental_scale = 24.0
        self.ultimate_base_reward = 20.0
        self.ultimate_quality_scale = 30.0
        self.ultimate_efficiency_scale = 0.3
        
        # ã€æ€§èƒ½ä¼˜åŒ–ã€‘åŸå§‹æ–‡ä»¶æ±‡ç¼–ç¼“å­˜ï¼ˆåŸå§‹æ–‡ä»¶ä¸å˜ï¼Œå¯å¤ç”¨ï¼‰
        # ç¼“å­˜é”®: (original_binary, function_name, ori_sym_addr)
        # ç¼“å­˜å€¼: æ±‡ç¼–æ–‡ä»¶è·¯å¾„
        self._original_asm_cache = {}
        
        # ã€æ€§èƒ½ä¼˜åŒ–ã€‘å¤ç”¨ä¸´æ—¶ç›®å½•ï¼Œé¿å…é¢‘ç¹åˆ›å»ºåˆ é™¤
        # åœ¨ save_path ä¸‹åˆ›å»ºå›ºå®šå·¥ä½œç›®å½•
        self._asm_work_dir = os.path.join(self.save_path, '_asm_work')
        os.makedirs(self._asm_work_dir, exist_ok=True)
        # ç‹¬ç«‹çš„å˜å¼‚è¾“å‡ºç›®å½•ï¼ˆé¿å…å¤šè¿›ç¨‹/å¤šå®éªŒäº’ç›¸æ±¡æŸ“ï¼‰
        self.output_dir = os.path.abspath(output_dir) if output_dir else os.path.join(self.save_path, 'rl_output')
        os.makedirs(self.output_dir, exist_ok=True)

        # å¥–åŠ±æœºåˆ¶
        # ã€å…³é”®ã€‘å›ºå®šæƒé‡ï¼Œä¸å†åŠ¨æ€è°ƒæ•´
        self.reward_weights = {
            'incremental': 1.0,   # åŸºç¡€æƒé‡
            'ultimate': 1.0,      # æˆåŠŸå¥–åŠ±å·²ç»å¾ˆå¤§äº†
            'penalty': 1.0        # æƒ©ç½šæƒé‡
        }
        # å¥–åŠ±è£å‰ªç»Ÿè®¡ï¼ˆç”¨äºåˆ¤æ–­å¥–åŠ±æ˜¯å¦ç»å¸¸è§¦é¡¶/è§¦åº•ï¼‰
        self._reward_clip_total = 0
        self._reward_clip_hi = 0
        self._reward_clip_lo = 0
        self.reward_clip_log_interval = 200

        # è®°å½•æ¯ä¸ªæ ·æœ¬çš„å†å²æˆåŠŸç‡
        # æ ¼å¼: {sample_id: deque(maxlen=10)}
        from collections import deque
        self.sample_history = {}

        # è®°å½•æ¯ä¸ªæ ·æœ¬çš„æƒé‡ (ç”¨äºé‡‡æ ·)
        # åˆå§‹æƒé‡éƒ½ä¸º 1.0
        self.sample_weights = np.ones(len(self.dataset))

        # å»ºç«‹ç´¢å¼•æ˜ å°„ (index -> sample_id) ä»¥ä¾¿æ›´æ–°æƒé‡
        self.idx_to_id = {}
        for idx, item in enumerate(self.dataset):
            s_id = f"{item['binary_name']}::{item['func_name']}::{item['version']}"
            self.idx_to_id[idx] = s_id
            self.sample_history[s_id] = deque(maxlen=10) # åªçœ‹æœ€è¿‘10æ¬¡
        # è®°å½•æ¯ä¸ªæ ·æœ¬çš„å†å²æœ€ä¼˜ä¸åœæ»è®¡æ•°ï¼ˆè‡ªé€‚åº”åˆ‡æ¢ï¼‰
        self.sample_best_score = {s_id: None for s_id in self.idx_to_id.values()}
        self.sample_no_progress = {s_id: 0 for s_id in self.idx_to_id.values()}

        self.current_sample_idx = 0 # è¿½è¸ªå½“å‰æ ·æœ¬åœ¨æ•°æ®é›†ä¸­çš„ç´¢å¼•
        self.current_difficulty = 0.5

        logger.info(
            f"Environment initialized (Hold Strategy: adaptive={self.adaptive_hold}, "
            f"hold_min={self.hold_min}, hold_max={self.hold_max}, stall_limit={self.stall_limit})"
        )

    def _find_sym_to_addr(self, binary_path):
        base_dir = os.path.dirname(os.path.abspath(binary_path))
        candidates = [
            os.path.join(base_dir, "sym_to_addr.pickle"),
            os.path.join(os.path.dirname(base_dir), "sym_to_addr.pickle"),
        ]
        for path in candidates:
            if os.path.exists(path):
                return path
        return None

    def _load_sym_to_addr(self, path):
        if not path or not os.path.exists(path):
            return {}
        try:
            with open(path, "rb") as f:
                return pickle.load(f)
        except Exception:
            return {}

    def _resolve_original_addr(self):
        if self.current_sample_data and "func_addr" in self.current_sample_data:
            return self.current_sample_data.get("func_addr")
        return None
    
    def set_state_dim(self, state_dim):
        """
        è®¾ç½®çŠ¶æ€ç»´åº¦ï¼ˆç”¨äºä¸ PPO Agent ä¿æŒä¸€è‡´ï¼‰
        
        å‚æ•°:
            state_dim: çŠ¶æ€ç»´åº¦
        """
        self.state_dim = state_dim
        logger.info(f"çŠ¶æ€ç»´åº¦è®¾ç½®ä¸º: {state_dim}")


    def _resolve_mutated_address(self, binary_path):
        """
        æ ¸å¿ƒè¾…åŠ©å‡½æ•°ï¼šè§£æå˜å¼‚åå‡½æ•°çš„çœŸå®åœ°å€
        è§£å†³ Strip æ–‡ä»¶æ— æ³•é€šè¿‡å‡½æ•°åå®šä½çš„é—®é¢˜
        """
        # 1. å¦‚æœæ˜¯åŸå§‹æ–‡ä»¶ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“åŸå§‹åœ°å€
        # è¿™é‡Œå‡è®¾åŸå§‹æ–‡ä»¶æœª Stripï¼Œæˆ–è€…ä½ èƒ½é€šè¿‡å‡½æ•°åæ‰¾åˆ°
        # print(f"[_resolve_mutated_address]:Resolving address for binary: {binary_path}")
        if binary_path == self.original_binary:
            return None, self.function_name

        # 2. å¯»æ‰¾ sym_to_addr.pickle æ˜ å°„æ–‡ä»¶
        mutated_dir = os.path.dirname(binary_path)
        pickle_path = os.path.join(mutated_dir, "sym_to_addr.pickle")
        
        # æœ‰æ—¶å€™ uroboros ä¼šç”Ÿæˆåœ¨ä¸Šä¸€çº§
        if not os.path.exists(pickle_path):
            pickle_path = os.path.join(os.path.dirname(mutated_dir), "sym_to_addr.pickle")

        if not os.path.exists(pickle_path):
            # å¦‚æœæ‰¾ä¸åˆ°æ˜ å°„ï¼Œåªèƒ½è¿”å› Noneï¼Œåç»­é€»è¾‘ä¼šå°è¯•ç›²çŒœå…¥å£ç‚¹
            # logger.warning(f"Map file missing for {binary_path}")
            return None, None

        try:
            with open(pickle_path, 'rb') as f:
                addr_map = pickle.load(f)

            # å°è¯•è·å–ç›®æ ‡å‡½æ•°çš„åœ°å€
            # Uroboros çš„ map key å¯èƒ½æ˜¯åŸå§‹å‡½æ•°å
            if self.function_name in addr_map:
                addr_str = addr_map[self.function_name]
                if isinstance(addr_str, str):
                    return int(addr_str, 16), None
                return int(addr_str), None
            
            # å¦‚æœæ‰¾ä¸åˆ°ç›´æ¥åŒ¹é…ï¼Œå°è¯•å¯»æ‰¾ 'func_xxxx' æ ¼å¼
            # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œè¿”å› None è®© r2 å°è¯• entry0
            return None, None
            
        except Exception as e:
            logger.error(f"Error resolving address: {e}")
            return None, None


    def extract_features_from_function(self, binary_path, function_name=None):
        """
        ç‰¹å¾æå–å‡½æ•° (256ç»´)
        ç»„æˆ: [å†å²ç‰¹å¾(16)] + [ACFGç‰¹å¾(240)]
        ç”¨äºç‰¹å¾æå–æ—¶ï¼ŒæŒ‡å®šå‡½æ•°åï¼Œè€Œä¸æ˜¯é€šè¿‡è§£æåœ°å€
        """
        features = []
        # ==========================================
        # Part 1: å˜å¼‚å†å²ä¸ç¯å¢ƒçŠ¶æ€ (16ç»´)
        # ==========================================
        # 1. Score History (5 dims)
        if self.mutation_history:
            scores = [m.get('score', 1.0) for m in self.mutation_history[-5:]]
            features.extend(scores)
            features.extend([1.0] * (5 - len(scores)))
        else:
            features.extend([1.0] * 5)
            
        # 2. Action Histogram (7 dims, action_id -> action_index)
        features.extend(self._action_histogram_features())
        
        # 3. Progress (2 dims)
        step_ratio = self.step_count / max(float(self.max_steps), 1.0)
        features.append(step_ratio)
        features.append(1.0 if step_ratio > 0.5 else 0.0)
        
        # 4. Global State (2 dims)
        features.append(1.0 if len(self.mutation_history) > 0 else 0.0) # Is Modified
        if self.include_schedule_feature:
            features.append(self.episodes_on_current / max(float(self.current_hold_limit), 1.0))
        else:
            features.append(0.0)

        # ==========================================
        # Part 2: åŸºäº Radare2 çš„ ACFG ç‰¹å¾ (æ ¸å¿ƒ)
        # ==========================================
        
        # åˆå§‹åŒ–é»˜è®¤å‘é‡ (å…¨0) ç”¨äºå¤±è´¥æƒ…å†µ
        acfg_vec = [0.0] * (self.state_dim - len(features))
        
        try:
            # 1. æ£€æŸ¥åœ°å€
            if function_name is None:
                raise Exception("function_name is None, please specify function_name")
            target_name = function_name
            target_addr = None
            # print(f"binary_path: {binary_path}")
            # print(f"[env_wrapper.py:extract_features_from_function] target_name: {target_name}, target_addr: {target_addr}")
            # 2. è°ƒç”¨ R2 æå–
            r2_ext = RadareACFGExtractor(binary_path)
            acfg_data = r2_ext.get_acfg_features(function_name=target_name, function_addr=target_addr)
            r2_ext.close()
            
            if acfg_data:
                # logger.debug(f"acfg_data: {acfg_data}")
                self.current_critical_blocks = self._select_top_blocks(acfg_data, k=3)
                self.current_all_blocks = list(acfg_data.get('basic_blocks', {}).keys())
                acfg_vec = self._vectorize_acfg(acfg_data)
            else:
                self.current_critical_blocks = []
                self.current_all_blocks = []
                
        except (FileNotFoundError, KeyError, ValueError, AttributeError) as e:
            logger.warning(f"Feature extraction failed for {binary_path}: {e}")
            self.current_critical_blocks = []
            self.current_all_blocks = []
            # ä¿æŒå…¨0
        
        features.extend(acfg_vec)
        
        # æœ€ç»ˆæˆªæ–­æˆ–è¡¥é½åˆ° 256 ç»´
        if len(features) > self.state_dim:
            features = features[:self.state_dim]
        elif len(features) < self.state_dim:
            features.extend([0.0] * (self.state_dim - len(features)))

        # === ã€æ ¸å¿ƒä¿®å¤ã€‘æ•°æ®æ¸…æ´— ===
        # 1. è½¬ä¸º numpy æ•°ç»„
        features = np.array(features, dtype=np.float32)
        
        # 2. æ›¿æ¢ NaN ä¸º 0ï¼Œæ›¿æ¢ Infinity ä¸ºæœ€å¤§/æœ€å°æœ‰é™å€¼
        # é˜²æ­¢ä»»ä½•è®¡ç®—é”™è¯¯äº§ç”Ÿçš„ NaN ä¼ å…¥ç¥ç»ç½‘ç»œ
        features = np.nan_to_num(features, nan=0.0, posinf=100.0, neginf=-100.0)

        features = self._apply_feature_mode(features)
        
        # 3. è£å‰ªæ•°å€¼èŒƒå›´ (Clip)
        # é˜²æ­¢æŸäº›ç‰¹å¾æ•°å€¼è¿‡å¤§ï¼ˆæ¯”å¦‚ total_instr çªç„¶å¾ˆå¤§ï¼‰ï¼Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        # å°†æ‰€æœ‰ç‰¹å¾é™åˆ¶åœ¨ [-10, 100] ä¹‹é—´é€šå¸¸è¶³å¤Ÿäº†
        features = np.clip(features, -10.0, 100.0)
            
        return features

    def _action_histogram_features(self):
        """
        å°†å†å²åŠ¨ä½œ(action_id)æ˜ å°„åˆ°ç¨³å®šçš„ç´¢å¼•ç©ºé—´(action_index)ï¼Œé¿å…æŠŠ action_id å½“ç´¢å¼•å¯¼è‡´ç»Ÿè®¡å¤±çœŸã€‚
        è¿”å›é•¿åº¦ä¸º 7 çš„å½’ä¸€åŒ–ç›´æ–¹å›¾ï¼ˆå›ºå®šå¸ƒå±€ï¼Œä¿è¯å†å²ç‰¹å¾æ€»ç»´åº¦ä¸å˜ï¼‰ã€‚
        """
        counts = np.zeros(self.hist_action_dim, dtype=np.float32)
        total = max(len(self.mutation_history), 1)

        for m in self.mutation_history:
            action_id = m.get('action')
            action_idx = self.hist_action_id_to_index.get(action_id)

            # å…¼å®¹æ—§æ•°æ®ï¼šå¦‚æœå†å²é‡Œå­˜çš„æ˜¯ç´¢å¼•è€Œä¸æ˜¯ action_idï¼Œåˆ™å›é€€ä¸ºç´¢å¼•ã€‚
            if action_idx is None and isinstance(action_id, int) and 0 <= action_id < self.hist_action_dim:
                action_idx = action_id

            if action_idx is not None:
                counts[action_idx] += 1.0

        return (counts / total).tolist()

    def _select_top_blocks(self, acfg_data, k=3):
        """
        é€‰æ‹© Top-K å…³é”®å—å¹¶ä¿æŒâ€œé‡è¦æ€§é¡ºåºâ€ã€‚
        - ä¼˜å…ˆä½¿ç”¨æå–å™¨è¿”å›çš„ top_critical_blocks é¡ºåºï¼›
        - è‹¥æ•°é‡ä¸è¶³ Kï¼ŒæŒ‰ critical_score/dominator/degree å…œåº•è¡¥é½ã€‚
        """
        try:
            k = max(1, int(k))
        except Exception:
            k = 3

        if not acfg_data:
            return []

        top_blocks = list(acfg_data.get('top_critical_blocks', []) or [])
        bbs = acfg_data.get('basic_blocks', {}) or {}

        ordered = []
        seen = set()
        for addr in top_blocks:
            if addr in seen:
                continue
            ordered.append(addr)
            seen.add(addr)
            if len(ordered) >= k:
                return ordered

        if isinstance(bbs, dict) and bbs:
            ranked = sorted(
                bbs.items(),
                key=lambda kv: (
                    -float(kv[1].get('critical_score', 0.0)),
                    -float(kv[1].get('dominator_score', 0.0)),
                    -float(kv[1].get('postdominator_score', 0.0)),
                    -float(kv[1].get('control_dependence_score', 0.0)),
                    -float(kv[1].get('loop_score', 0.0)),
                    -float(kv[1].get('centrality_degree', 0.0)),
                    kv[0],
                )
            )
            for addr, _ in ranked:
                if addr in seen:
                    continue
                ordered.append(addr)
                seen.add(addr)
                if len(ordered) >= k:
                    break

        return ordered[:k]

    def _apply_feature_mode(self, features):
        if self.feature_mode == "full":
            return features
        feats = features.copy()
        if self.state_dim < 256 or len(feats) < 16:
            return feats
        if self.feature_mode in ("no_progress", "no_progress_api", "no_section_c"):
            feats[12:16] = 0.0
        if self.feature_mode in ("no_api", "no_progress_api"):
            c_start = 16 + 40 + 160
            api_start = c_start + 8
            api_end = c_start + 30
            if api_end < len(feats):
                feats[api_start:api_end + 1] = 0.0
        if self.feature_mode == "no_section_c":
            c_start = 16 + 40 + 160
            if c_start < len(feats):
                feats[c_start:] = 0.0
        return feats

    def extract_features(self, binary_path):
        """
        ç‰¹å¾æå–å‡½æ•°
        ç»„æˆ: [å†å²ç‰¹å¾(16)] + [ACFGç‰¹å¾(240)]
        """
        features = []
        
        # ==========================================
        # Part 1: å˜å¼‚å†å²ä¸ç¯å¢ƒçŠ¶æ€ (16ç»´)
        # ==========================================
        # 1. Score History (5 dims)
        if self.mutation_history:
            scores = [m.get('score', 1.0) for m in self.mutation_history[-5:]]
            features.extend(scores)
            features.extend([1.0] * (5 - len(scores)))
        else:
            features.extend([1.0] * 5)
            
        # 2. Action Histogram (7 dims, action_id -> action_index)
        features.extend(self._action_histogram_features())
        
        # 3. Progress (2 dims)
        step_ratio = self.step_count / max(float(self.max_steps), 1.0)
        features.append(step_ratio)
        features.append(1.0 if step_ratio > 0.5 else 0.0)
        
        # 4. Global State (2 dims)
        features.append(1.0 if len(self.mutation_history) > 0 else 0.0) # Is Modified
        if self.include_schedule_feature:
            features.append(self.episodes_on_current / max(float(self.current_hold_limit), 1.0))
        else:
            features.append(0.0)

        # ==========================================
        # Part 2: åŸºäº Radare2 çš„ ACFG ç‰¹å¾ (æ ¸å¿ƒ)
        # ==========================================
        
        # åˆå§‹åŒ–é»˜è®¤å‘é‡ (å…¨0) ç”¨äºå¤±è´¥æƒ…å†µ
        acfg_vec = [0.0] * (self.state_dim - len(features))
        
        try:
            # 1. è§£æåœ°å€
            # print("[extract_features]:binary_path:", binary_path)
            target_addr, target_name = self._resolve_mutated_address(binary_path)
            # print(f"target_addr: {target_addr}, target_name: {target_name}")
            # 2. è°ƒç”¨ R2 æå–
            r2_ext = RadareACFGExtractor(binary_path)
            acfg_data = r2_ext.get_acfg_features(function_name=target_name, function_addr=target_addr)
            r2_ext.close()
            
            if acfg_data:
                # ä¿æŒé‡è¦æ€§é¡ºåºï¼Œé¿å…åœ°å€æ’åºæ‰“ä¹± Top-1/2/3 çš„è¯­ä¹‰ã€‚
                self.current_critical_blocks = self._select_top_blocks(acfg_data, k=3)
                self.current_all_blocks = list(acfg_data.get('basic_blocks', {}).keys())
                acfg_vec = self._vectorize_acfg(acfg_data)
            else:
                self.current_critical_blocks = []
                self.current_all_blocks = []
                
                
        except (FileNotFoundError, KeyError, ValueError, AttributeError) as e:
            logger.warning(f"Feature extraction failed for {binary_path}: {e}")
            self.current_critical_blocks = []
            self.current_all_blocks = []
            # ä¿æŒå…¨0
        
        features.extend(acfg_vec)
        
        # æœ€ç»ˆæˆªæ–­æˆ–è¡¥é½
        if len(features) > self.state_dim:
            features = features[:self.state_dim]
        elif len(features) < self.state_dim:
            features.extend([0.0] * (self.state_dim - len(features)))

        # === ã€æ ¸å¿ƒä¿®å¤ã€‘æ•°æ®æ¸…æ´— ===
        # 1. è½¬ä¸º numpy æ•°ç»„
        features = np.array(features, dtype=np.float32)
        
        # 2. æ›¿æ¢ NaN ä¸º 0ï¼Œæ›¿æ¢ Infinity ä¸ºæœ€å¤§/æœ€å°æœ‰é™å€¼
        # é˜²æ­¢ä»»ä½•è®¡ç®—é”™è¯¯äº§ç”Ÿçš„ NaN ä¼ å…¥ç¥ç»ç½‘ç»œ
        features = np.nan_to_num(features, nan=0.0, posinf=100.0, neginf=-100.0)

        features = self._apply_feature_mode(features)
        
        # 3. è£å‰ªæ•°å€¼èŒƒå›´ (Clip)
        # é˜²æ­¢æŸäº›ç‰¹å¾æ•°å€¼è¿‡å¤§ï¼ˆæ¯”å¦‚ total_instr çªç„¶å¾ˆå¤§ï¼‰ï¼Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸
        # å°†æ‰€æœ‰ç‰¹å¾é™åˆ¶åœ¨ [-10, 100] ä¹‹é—´é€šå¸¸è¶³å¤Ÿäº†
        features = np.clip(features, -10.0, 100.0)
            
        return features
    

    def _vectorize_acfg(self, data, state_dim=256):
        """
        ã€ç»ˆæä¿®å¤ç‰ˆã€‘
        Part 1 (16ç»´): RL History (å·²åœ¨å¤–éƒ¨å¡«å……)
        Part 2 (40ç»´): Section A - Macro Topology
        Part 3 (160ç»´): Section B - Critical Semantics (Micro)
        Part 4 (40ç»´): Section C - Global Semantics (Macro & Fingerprints)
        Total: 16 + 40 + 160 + 40 = 256 ç»´
        """
        vec = []
        
        n_nodes = max(data.get('num_nodes', 0), 1.0)
        n_edges = data.get('num_edges', 0)
        complexity = data.get('cyclomatic_complexity', 0)
        bbs = list(data.get('basic_blocks', {}).values())
        # ä¿æŒæå–å™¨ç»™å‡ºçš„é‡è¦æ€§é¡ºåºï¼ˆTop-1/2/3ï¼‰ï¼Œå¹¶åœ¨ç¼ºå¤±æ—¶åšå…œåº•è¡¥é½ã€‚
        stable_top_addrs = self._select_top_blocks(data, k=3)
        fingerprints = data.get('fingerprints', {})
        
        # === ã€æ ¸å¿ƒä¿®æ­£1ã€‘è®¡ç®—â€œæœ‰æ•ˆæŒ‡ä»¤æ€»æ•°â€ (Effective Total) ===
        # æˆ‘ä»¬ä¸å…³å¿ƒ MOV/PUSH/POPï¼Œåªå…³å¿ƒçœŸæ­£å¹²æ´»çš„æŒ‡ä»¤
        # è¿™æ ·åˆ†æ¯åœ¨ O0/O3 ä¹‹é—´ä¼šç›¸å¯¹ç¨³å®š
        effective_keys = ['n_arith', 'n_logic', 'n_branch', 'n_cmp', 'n_xor', 'n_shift', 'n_consts', 'n_call']
        
        total_effective_instr = 0
        for b in bbs:
            for k in effective_keys:
                total_effective_instr += b.get(k, 0)
        # åŠ ä¸Š API è°ƒç”¨ (è¿™ä¹Ÿæ˜¯æœ‰æ•ˆé€»è¾‘)
        total_effective_instr += fingerprints.get('n_calls', 0)
        
        safe_eff_total = max(total_effective_instr, 1.0)
        
        # è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨æœ‰æ•ˆæ€»æ•°è¿›è¡Œå½’ä¸€åŒ–
        def safe_div_eff(a): return a / safe_eff_total

        # ==========================================
        # Section A: Macro Topology (40 dims)
        # ==========================================
        # 1. Scale (8 dims)
        vec.append(np.log1p(n_nodes))
        vec.append(np.log1p(n_edges))
        vec.append(n_edges / n_nodes if n_nodes > 0 else 0) 
        vec.append(np.log1p(max(complexity, 0.0)))
        vec.append(complexity / n_nodes if n_nodes > 0 else 0)
        
        # Leaf / Branch nodes ratio
        leaf_cnt = sum(1 for b in bbs if b.get('n_branch', 0) == 0)
        branch_cnt = sum(1 for b in bbs if b.get('n_branch', 0) > 1)
        vec.append(leaf_cnt / n_nodes)
        vec.append(branch_cnt / n_nodes)

        # Effective Size (Log) -> æ›¿ä»£åŸæ¥çš„ Total Size
        vec.append(np.log1p(total_effective_instr))

        # 2. Distributions (32 dims)
        # ã€ä¿®æ­£ã€‘ç»Ÿä¸€ä½¿ç”¨ log1p å¤„ç† Momentsï¼Œé˜²æ­¢æ•°å€¼çˆ†ç‚¸
        def get_moments_log(values):
            if not values: return [0.0]*4
            arr = np.array(values)
            # å¯¹åŸå§‹å€¼å– log1p åå†ç®—çŸ©ï¼Œæ‹‰å¹³é‡çº²
            log_arr = np.log1p(np.maximum(arr, 0.0))
            return [np.mean(log_arr), np.max(log_arr), np.std(log_arr), np.median(log_arr)]

        dist_bet = [b.get('centrality_betweenness', 0) for b in bbs]
        dist_deg = [b.get('centrality_degree', 0) for b in bbs]
        dist_dom = [b.get('dominator_score', 0) for b in bbs]
        dist_eff_size = []

        for b in bbs:
            eff = sum(b.get(k, 0) for k in effective_keys)
            dist_eff_size.append(eff)

        for dist in [dist_bet, dist_deg, dist_dom, dist_eff_size]:
            vec.extend(get_moments_log(dist)) # 4 dims
            s_dist = sorted(dist, reverse=True)
            # Top-4 values
            top4 = s_dist[:4] + [0.0]*(4-len(s_dist))
            if dist is dist_dom or dist is dist_eff_size:
                vec.extend([np.log1p(x) for x in top4])
            else:
                vec.extend(top4)
        
        # Section A Total: 8 + 4*8 = 40. Correct.

        # ==========================================
        # Section B: Critical Semantics (160 dims)
        # ==========================================
        crit_vectors = []
        # print(f"top_critical_addrs: {top_critical_addrs}")
        # === å®šä¹‰å®‰å…¨é™¤æ³•è¾…åŠ©å‡½æ•° ===
        def safe_div(a, b):
            """
            å®‰å…¨é™¤æ³•ï¼šå¦‚æœåˆ†æ¯ä¸º0æˆ–éå¸¸å°ï¼Œè¿”å›0.0ï¼Œå¦åˆ™è¿”å› a/bã€‚
            """
            # ä½¿ç”¨ä¸€ä¸ªæå°å€¼ epsilon (1e-9) é˜²æ­¢æµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜ï¼Œæˆ–è€…ç›´æ¥åˆ¤æ–­ > 0
            return a / b if abs(b) > 1e-9 else 0.0
        # å®šä¹‰æœ‰æ•ˆæŒ‡ä»¤é›† (ç”¨äºè®¡ç®—åˆ†æ¯ï¼Œå‰”é™¤å™ªå£°)
        effective_keys = ['n_arith', 'n_logic', 'n_branch', 'n_cmp', 'n_xor', 'n_shift', 'n_consts']
        
        # éå† Top-3 å…³é”®å— (å¦‚æœä¸è¶³3ä¸ªï¼Œå¾ªç¯ä¼šè‡ªåŠ¨ç»“æŸ)
        for addr in stable_top_addrs:
            if addr not in data.get('basic_blocks', {}): continue
            bb = data['basic_blocks'][addr]
            
            # è®¡ç®—è¯¥å—çš„æœ‰æ•ˆæŒ‡ä»¤æ•° (åˆ†æ¯)
            bb_eff = sum(bb.get(k, 0) for k in effective_keys)
            safe_bb_eff = max(bb_eff, 1.0)
            n_inst = max(bb.get('n_instructions', 0), 1.0) # ç‰©ç†æŒ‡ä»¤æ•°
            
            v = []
            
            # --- [1] è§„æ¨¡ä¸åŸºç¡€æ¯”ç‡ (9 dims) ---
            v.append(np.log1p(bb_eff))                         # 0. Effective Size (Log)
            v.append(bb.get('n_arith', 0) / safe_bb_eff)       # 1. Arith Ratio
            v.append(bb.get('n_logic', 0) / safe_bb_eff)       # 2. Logic Ratio
            v.append(bb.get('n_branch', 0) / safe_bb_eff)      # 3. Branch Ratio
            v.append(bb.get('n_cmp', 0) / safe_bb_eff)         # 4. Cmp Ratio
            v.append(bb.get('n_xor', 0) / safe_bb_eff)         # 5. Xor Ratio (Crypto feature)
            v.append(bb.get('n_shift', 0) / safe_bb_eff)       # 6. Shift Ratio (Crypto feature)
            v.append(bb.get('n_consts', 0) / safe_bb_eff)      # 7. Constant Ratio
            v.append(bb.get('n_transfer', 0) / n_inst)         # 8. Transfer Density (æ¬è¿æŒ‡ä»¤å æ¯”)

            # --- [2] æ•°æ®æµä¸èµ„æº (5 dims) ---
            v.append(safe_div(bb.get('n_regs_gp', 0), 16.0))   # 9. GP Reg Pressure
            v.append(safe_div(bb.get('n_regs_vec', 0), 16.0))  # 10. Vector Reg Pressure (SIMD)
            v.append(safe_div(bb.get('n_mem_write', 0), n_inst)) # 11. Mem Write Intensity
            v.append(safe_div(bb.get('n_mem_read', 0), n_inst))  # 12. Mem Read Intensity
            # 13. Compute/Mem Ratio (è®¡ç®—å¯†é›†åº¦)
            compute_ops = bb.get('n_arith', 0) + bb.get('n_logic', 0)
            mem_ops = bb.get('n_mem_write', 0) + bb.get('n_mem_read', 0)
            v.append(safe_div(compute_ops, mem_ops + 1.0))
            
            # --- [3] æ‹“æ‰‘ä¸ä¸­å¿ƒæ€§ (6 dims) ---
            v.append(bb.get('centrality_betweenness', 0))         # 14. Betweenness
            v.append(bb.get('centrality_degree', 0))              # 15. Degree
            v.append(np.log1p(bb.get('dominator_score', 0)))      # 16. Dom Score
            v.append(np.log1p(bb.get('postdominator_score', 0)))  # 17. Post-Dom Score
            v.append(np.log1p(bb.get('control_dependence_score', 0)))  # 18. CDG Score
            v.append(bb.get('critical_score', 0))                 # 19. Aggregated Score
            
            # --- [4] ç»“æ„æ ‡å¿—ä½ (3 dims) ---
            v.append(1.0 if bb.get('n_consts', 0) > 0 else 0.0)      # 20. Has Constant?
            v.append(1.0 if bb.get('n_branch', 0) > 1 else 0.0)      # 21. Is Multi-Branch?
            v.append(1.0 if compute_ops > mem_ops else 0.0)          # 22. Is Compute Heavy?
            
            # --- [5] é«˜çº§ç»„åˆç‰¹å¾ (9 dims, å¡«æ»¡32) ---
            # 23. Entropy Proxy (æ“ä½œç ç§ç±»ä¸°å¯Œåº¦)
            uniq_types = sum(1 for k in effective_keys if bb.get(k, 0) > 0)
            v.append(uniq_types / 7.0)
            
            # 24. Stack Heaviness (æ˜¯å¦ä¸»è¦æ˜¯æ ˆæ“ä½œ)
            v.append(1.0 if bb.get('n_transfer', 0) > n_inst * 0.5 else 0.0)
            
            # 25. Loop Header Heuristic (æœ‰è·³è½¬ä¸”åœ¨ç¯ä¸­)
            is_loop = 1.0 if (
                bb.get('n_branch', 0) > 0 and (
                    bb.get('is_in_loop', 0.0) > 0.5 or bb.get('loop_score', 0) > 1
                )
            ) else 0.0
            v.append(is_loop)
            
            # 26. Logic+Xor Density (æ··æ·†å¸¸è§ç‰¹å¾)
            v.append(safe_div(bb.get('n_logic', 0) + bb.get('n_xor', 0), safe_bb_eff))
            
            # 27. Write/Read Ratio (å†™å¤šè¯»å°‘å¯èƒ½æ˜¯åˆå§‹åŒ–)
            v.append(safe_div(bb.get('n_mem_write', 0), bb.get('n_mem_read', 0) + 1.0))
            
            # 28. Arith/Logic Ratio
            v.append(safe_div(bb.get('n_arith', 0), bb.get('n_logic', 0) + 1.0))
            
            # 29. Branch/Compute Ratio (æ§åˆ¶æµå¯†é›†åº¦)
            v.append(safe_div(bb.get('n_branch', 0), compute_ops + 1.0))
            
            # 30. Reg Diversity (é€šç”¨+å‘é‡å¯„å­˜å™¨æ€»æ•°å½’ä¸€åŒ–)
            v.append(safe_div(bb.get('n_regs_gp', 0) + bb.get('n_regs_vec', 0), 16.0))
            
            # 31. Tiny Block Flag (æ˜¯å¦æå°å—ï¼Œå¦‚Trampoline)
            v.append(1.0 if n_inst < 5 else 0.0)

            # ç¡®ä¿é•¿åº¦ä¸º 32
            v = v[:32] 
            crit_vectors.append(v)

        # === æ‰å¹³åŒ–å¡«å…… (Top-1, Top-2, Top-3) ===
        # å ç”¨ 32 * 3 = 96 ç»´
        for i in range(3):
            if i < len(crit_vectors):
                vec.extend(crit_vectors[i])
            else:
                # å¦‚æœæ²¡æœ‰è¿™ä¸ªå—ï¼ˆæ¯”å¦‚å‡½æ•°å¾ˆå°ï¼‰ï¼Œè¡¥ 0
                vec.extend([0.0] * 32)
        
        # === å…¨å±€èšåˆä¸Šä¸‹æ–‡ (Context) ===
        # å ç”¨ 32 * 2 = 64 ç»´
        if crit_vectors:
            mat = np.array(crit_vectors)
            vec.extend(np.mean(mat, axis=0)) # Global Mean of Critical Areas
            vec.extend(np.max(mat, axis=0))  # Global Max of Critical Areas
        else:
            vec.extend([0.0] * 64)

        # ==========================================
        # === Section C: Global Semantics (40 dims) ===
        # ==========================================
        
        # 1. Global Logic Ratios (8 dims)
        # åªç»Ÿè®¡é€»è¾‘æŒ‡ä»¤ï¼Œå¿½ç•¥æ•°æ®æ¬è¿
        global_sums = {k: sum(b.get(k, 0) for b in bbs) for k in effective_keys}
        for k in effective_keys:
            vec.append(global_sums[k] / safe_eff_total)
        # è¡¥ 1 ç»´ï¼šå…¨å±€ç¯å—æ¯”ä¾‹ (æ›¿ä»£å ä½å¸¸é‡)
        loop_block_ratio = (
            sum(1 for b in bbs if float(b.get('is_in_loop', 0.0)) > 0.5) / n_nodes
            if bbs else 0.0
        )
        vec.append(loop_block_ratio)
            
        # 2. API & Strings (22 dims)
        vec.append(np.log1p(fingerprints.get('n_calls', 0)))
        vec.append(np.log1p(fingerprints.get('n_strings', 0)))
        # ç›¸å¯¹äºæœ‰æ•ˆæŒ‡ä»¤çš„å¯†åº¦
        vec.append(fingerprints.get('n_calls', 0) / safe_eff_total)
        vec.append(fingerprints.get('n_strings', 0) / safe_eff_total)
        
        api_cats = ['io', 'mem', 'str', 'sys', 'net', 'crypto', 'error', 'other', 'internal']
        apis = fingerprints.get('api_types', set())
        # 9 dims: API ç±»åˆ« flags
        for cat in api_cats:
            vec.append(1.0 if cat in apis else 0.0)
        # 9 dims: åŸæœ¬æ’å®š 0 -> æ›¿æ¢ä¸ºçœŸå®ç»Ÿè®¡
        n_ops_imm = fingerprints.get('n_ops_imm', 0)
        n_ops_reg = fingerprints.get('n_ops_reg', 0)
        n_ops_mem = fingerprints.get('n_ops_mem', 0)
        total_ops = max(n_ops_imm + n_ops_reg + n_ops_mem, 1.0)
        op_imm_ratio = n_ops_imm / total_ops
        op_reg_ratio = n_ops_reg / total_ops
        op_mem_ratio = n_ops_mem / total_ops

        consts = fingerprints.get('consts', [])
        if consts:
            abs_consts = [abs(v) for v in consts]
            log_abs = [np.log1p(v) for v in abs_consts]
            mean_abs_log = float(np.mean(log_abs))
            max_abs_log = float(np.max(log_abs))
            pos_cnt = sum(1 for v in consts if v > 0)
            neg_cnt = sum(1 for v in consts if v < 0)
            const_pos_ratio = pos_cnt / (neg_cnt + 1.0)
            const_unique_ratio = len(set(consts)) / (len(consts) + 1.0)
            const_small_ratio = sum(1 for v in abs_consts if v <= 255) / (len(consts) + 1.0)
            n_consts_log = float(np.log1p(len(consts)))
        else:
            mean_abs_log = 0.0
            max_abs_log = 0.0
            const_pos_ratio = 0.0
            const_unique_ratio = 0.0
            const_small_ratio = 0.0
            n_consts_log = 0.0

        vec.extend([
            op_imm_ratio,
            op_reg_ratio,
            op_mem_ratio,
            n_consts_log,
            mean_abs_log,
            max_abs_log,
            const_pos_ratio,
            const_unique_ratio,
            const_small_ratio,
        ])
            
        # 3. Block Size Dist (5 dims) - åŸºäº Effective Size
        sizes = [sum(b.get(k, 0) for k in effective_keys) for b in bbs]
        if sizes:
            vec.append(sum(1 for s in sizes if s < 2) / len(sizes)) # Tiny logic
            vec.append(sum(1 for s in sizes if 2 <= s < 10) / len(sizes)) 
            vec.append(sum(1 for s in sizes if 10 <= s < 30) / len(sizes))
            vec.append(sum(1 for s in sizes if s >= 30) / len(sizes))
            vec.append(np.max(sizes) / safe_eff_total)
        else:
            vec.extend([0.0] * 5)
            
        # 4. Global Logic Ratios (Logic/Arith etc.) (5 dims)
        vec.append(global_sums['n_arith'] / (global_sums['n_logic'] + 1.0))
        vec.append(global_sums['n_branch'] / (global_sums['n_arith'] + 1.0))
        vec.append(global_sums['n_consts'] / safe_eff_total)
        vec.append(1.0 if global_sums['n_consts'] > 3 else 0.0)
        vec.append(1.0 if global_sums['n_shift'] > 0 else 0.0) # Crypto hint
        
        # Section C Total: 8 + 22 + 5 + 5 = 40 dims
        # ACFG Total: 40 + 160 + 40 = 240 dims
        
        return vec


    
    def apply_mutation(self, seed_binary, action, target_addr):
        """
        åº”ç”¨å˜å¼‚æ“ä½œ
        
        å‚æ•°:
            seed_binary: ç§å­äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            action: å˜å¼‚æ¨¡å¼ (1,2,4,7,8,9,11,13,14,15,16)
            target_addr: æ”»å‡»ä½ç½®åœ°å€
        è¿”å›:
            mutated_binary: å˜å¼‚åçš„äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
        """
        try:
            if self.function_name == 'main':
                logger.warning("Skip mutation for function 'main' (avoid unstable target)")
                return None, None
            # è®°å½•è°ƒç”¨æ—¶çš„ step_countï¼Œç”¨äºè°ƒè¯•
            current_step = getattr(self, 'step_count', 'unknown')
            logger.info("Applying mutation {} to {} (step={})".format(action, os.path.basename(seed_binary), current_step))
            
            # ç”Ÿæˆä¸´æ—¶äºŒè¿›åˆ¶æ–‡ä»¶å
            tmp_bin = os.path.join(self.output_dir, 'mutant_' + str(int(time.time() * 1000)) + '.bin')
            
            # ç¡®å®šæ¨¡å¼
            fmode = 'mutated' if seed_binary != self.original_binary else 'original'
            
            # ä¸ºæ¯æ¬¡å˜å¼‚åˆ›å»ºç‹¬ç«‹çš„ä¸´æ—¶ç›®å½•
            tmp_id = str(int(time.time() * 1000))
            tmp_dir = os.path.join(self.save_path, 'tmp_' + tmp_id)
            os.makedirs(tmp_dir, exist_ok=True)
            
            # è°ƒç”¨ uroboros (Python 2) è¿›è¡Œå˜å¼‚
            # æ³¨æ„ï¼šè¿™é‡Œå¿…é¡»ä½¿ç”¨ python2ï¼Œå› ä¸º uroboros æ˜¯ Python 2 ä»£ç 
            cmd = [
                'python2',
                os.path.join(self.project_root, 'uroboros_automate-func-name.py'),
                seed_binary,
                '-i', '1',  # è¿­ä»£æ¬¡æ•°
                '-o', tmp_bin,
                '-d', str(action),
                '-m', fmode,
                '-f', tmp_dir,
                '--function', self.function_name
            ]
            
            if target_addr is not None:
                # ç¡®ä¿è½¬ä¸º hex å­—ç¬¦ä¸²
                hex_addr = hex(target_addr) if isinstance(target_addr, int) else str(target_addr)
                cmd.extend(['--target_addr', hex_addr])
                # logger.debug(f"ğŸ¯ Targeting specific block: {hex_addr}")

            logger.debug("Command: " + " ".join(cmd))
            
            # åœ¨é¡¹ç›®æ ¹ç›®å½•æ‰§è¡Œå‘½ä»¤
            try:
                output = subprocess.check_output(
                    cmd, 
                    stderr=subprocess.STDOUT,
                    cwd=self.project_root,
                    universal_newlines=True  # è¿”å›å­—ç¬¦ä¸²è€Œä¸æ˜¯å­—èŠ‚
                )
                logger.debug("Uroboros output: {}".format(output))
            except subprocess.CalledProcessError as e:
                # æ•è·è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                error_output = e.output if hasattr(e, 'output') else str(e)
                logger.error("Uroboros command failed with exit code {}: {}".format(e.returncode, error_output))
                logger.error("Command was: {}".format(" ".join(cmd)))
                raise Exception("Uroboros mutation failed: {}\nOutput: {}".format(e, error_output))
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(tmp_bin):
                raise FileNotFoundError("Mutation output not found: {}".format(tmp_bin))
            
            # è®¡ç®— hash å¹¶ç§»åŠ¨æ–‡ä»¶
            h = hashlib.md5(open(tmp_bin, 'rb').read()).hexdigest()
            container_path = os.path.join(self.save_path, h + '_container')
            
            if not os.path.exists(container_path):
                # ç§»åŠ¨ tmp ç›®å½•åˆ° container
                import shutil
                shutil.move(tmp_dir, container_path)
                # ç§»åŠ¨äºŒè¿›åˆ¶æ–‡ä»¶
                shutil.move(tmp_bin, os.path.join(container_path, h))
            
            mutated_binary = os.path.join(container_path, h)
            logger.info("Mutation successful: {}".format(mutated_binary))
            
            return mutated_binary, h
            
        except Exception as e:
            logger.error("Mutation failed: {}".format(e))
            return None, None
    
    def evaluate(self, mutated_binary, checkdict):
        """
        è¯„ä¼°å˜å¼‚åçš„äºŒè¿›åˆ¶æ–‡ä»¶
        
        è¿”å›:
            score: ç›¸ä¼¼åº¦åˆ†æ•°
            grad: æ¢¯åº¦å€¼
        """
        try:
            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘ä¼ é€’å·¥ä½œç›®å½•å’Œç¼“å­˜ï¼Œé¿å…æ¯æ¬¡åˆ›å»ºä¸´æ—¶ç›®å½•
            mutated_func_addr = None
            if self.detection_method == "safe":
                if self.original_func_addr is None:
                    self.original_func_addr = self._resolve_original_addr()
                # print(f"[evaluate]:mutated_binary: {mutated_binary}")
                mutated_func_addr, _ = self._resolve_mutated_address(mutated_binary)
                # print(f"[evaluate]:mutated_func_addr: {mutated_func_addr}")
            score, grad = run_one(
                self.original_binary,
                mutated_binary,
                self.model_original,
                checkdict,
                self.function_name,
                detection_method=self.detection_method,
                asm_work_dir=self._asm_work_dir,
                original_asm_cache=self._original_asm_cache,
                original_func_addr=self.original_func_addr,
                mutated_func_addr=mutated_func_addr,
                safe_checkpoint_dir=self.safe_checkpoint_dir,
                safe_i2v_dir=self.safe_i2v_dir,
                safe_use_gpu=self.safe_use_gpu,
                safe_cache=self.safe_cache,
                jtrans_model_dir=self.jtrans_model_dir,
                jtrans_tokenizer_dir=self.jtrans_tokenizer_dir,
                jtrans_use_gpu=self.jtrans_use_gpu,
                jtrans_cache=self._jtrans_cache,
            )
            if self.detection_method == "safe":
                logger.success(f"[SAFE] eval_score={score}")
            elif self.detection_method == "jtrans":
                logger.success(f"[JTRANS] eval_score={score}")
            else:
                logger.debug(f"[ASM2VEC] eval_score={score}")
            if score is None or grad is None:
                logger.warning("Evaluation returned None")
                return 1.0, 0.0  # é»˜è®¤æœ€å·®å€¼
            
            return abs(score), abs(grad)
            
        except Exception as e:
            logger.error("Evaluation failed: {}".format(e))
            return 1.0, 0.0
    
    def step(self, action, loc_idx):
        """
        æ‰§è¡Œä¸€æ­¥ç¯å¢ƒäº¤äº’
        
        å‚æ•°:
            action: å˜å¼‚æ¨¡å¼
            loc_idx: æ”»å‡»ä½ç½®ç´¢å¼•
        
        è¿”å›:
            state: æ–°çŠ¶æ€ç‰¹å¾
            reward: å¥–åŠ±
            done: æ˜¯å¦å®Œæˆ
            info: é¢å¤–ä¿¡æ¯
        """
        # input("Press Enter to continue step...")
        self.step_count += 1
        # è®°å½•ä¸Šä¸€æ­¥åˆ†æ•°ï¼Œç”¨äºè®¡ç®—å·®åˆ†å¥–åŠ±
        prev_score = self.mutation_history[-1]['score'] if self.mutation_history else 1.0
        # === ã€æ ¸å¿ƒé€»è¾‘ã€‘è§£ææ”»å‡»ä½ç½® ===
        target_addr = None

        # ä½ç½®é€‰æ‹©ï¼š
        # - æœ‰å…³é”®å—æ—¶ï¼Œloc_idx å¿…é¡»å‘½ä¸­ Top-N
        # - æ— å…³é”®å—æ—¶ï¼Œé€€å›ä»»æ„å—é¿å…ç¯å¢ƒåƒµæ­»
        loc_valid = False
        if self.current_critical_blocks:
            if 0 <= loc_idx < len(self.current_critical_blocks):
                target_addr = self.current_critical_blocks[loc_idx]
                loc_valid = True
            elif not self.strict_invalid_loc and self.current_all_blocks:
                # å¯é€‰å…¼å®¹æ¨¡å¼ï¼šæ— æ•ˆ loc_idx æ—¶éšæœºå…œåº•
                target_addr = random.choice(self.current_all_blocks)
                loc_valid = True
        else:
            if self.current_all_blocks:
                target_addr = random.choice(self.current_all_blocks)
                loc_valid = True

        if not loc_valid and self.current_critical_blocks and self.strict_invalid_loc:
            # ä¸¥æ ¼æ¨¡å¼ï¼šä½ç½®è¶Šç•Œç›´æ¥æƒ©ç½šå¹¶è¿”å›ï¼Œä¸å†ç”¨éšæœºå…œåº•æ©ç›–é”™è¯¯åŠ¨ä½œã€‚
            logger.debug(
                f"Invalid loc_idx={loc_idx} for top_blocks={len(self.current_critical_blocks)}; strict penalty."
            )
            self.invalid_loc_streak += 1
            self.no_change_streak += 1
            state = self.extract_features(self.current_binary)
            reward = self.compute_reward_v2(
                prev_score,
                prev_score,
                self.step_count,
                invalid_loc=True,
                no_change=True,
                no_change_streak=self.no_change_streak,
                invalid_streak=self.invalid_loc_streak,
            )
            done = self.step_count >= self.max_steps
            info = {
                'score': prev_score,
                'grad': 0.0,
                'step': self.step_count,
                'binary': self.current_binary,
                'target_func': self.function_name,
                'loc_valid': False,
                'no_change': True,
                'no_change_streak': self.no_change_streak,
                'invalid_loc_streak': self.invalid_loc_streak,
                'score_delta': 0.0,
                'error': 'invalid_loc',
            }
            return state, reward, done, info

        # åº”ç”¨å˜å¼‚
        mutated_binary, hash_val = self.apply_mutation(self.current_binary, action, target_addr)
        logger.info(f"[step] apply_mutation returned, step={self.step_count}")
        # input("press enter to continue")
        if mutated_binary is None:
            # å˜å¼‚å¤±è´¥ï¼šæ ‡è®°éœ€è¦é‡ç½®ç¯å¢ƒå¹¶åˆ‡æ¢æ–‡ä»¶
            logger.warning("Mutation failed, will reset environment and switch to new file")
            state = self.extract_features(self.current_binary)
            return state, -10.0, True, {
                'error': 'mutation_failed',
                'should_reset': True,  # æ ‡å¿—ï¼šéœ€è¦é‡ç½®å¹¶åˆ‡æ¢æ–‡ä»¶
                'score': 1.0,  # é»˜è®¤æœ€å·®åˆ†æ•°
                'grad': 0.0
            }
        
        # è¯„ä¼°
        # TODO: è·å–æ­£ç¡®çš„ checkdict
        checkdict = {}  # éœ€è¦ä»å®é™…æ–‡ä»¶ä¸­åŠ è½½
        score, grad = self.evaluate(mutated_binary, checkdict)
        
        # æ›´æ–°çŠ¶æ€
        self.current_binary = mutated_binary
        self.mutation_history.append({
            'step': self.step_count,
            'action': action,
            'binary': mutated_binary,
            'hash': hash_val,
            'score': score,
            'grad': grad
        })
        
        # æå–æ–°çŠ¶æ€ç‰¹å¾
        state = self.extract_features(mutated_binary)
        
        # è®¡ç®—å¥–åŠ±
        score_delta = prev_score - score
        no_change = abs(score_delta) <= self.no_change_eps
        if no_change:
            self.no_change_streak += 1
        else:
            self.no_change_streak = 0
        if loc_valid:
            self.invalid_loc_streak = 0
        else:
            self.invalid_loc_streak += 1
        reward = self.compute_reward_v2(
            prev_score,
            score,
            self.step_count,
            invalid_loc=not loc_valid,
            no_change=no_change,
            no_change_streak=self.no_change_streak,
            invalid_streak=self.invalid_loc_streak,
        )
        # reward = self.compute_reward(score, grad)
        
        # åˆ¤æ–­æ˜¯å¦å®Œæˆ
        done = score < self.target_score or self.step_count >= self.max_steps

        info = {
            'score': score,
            'grad': grad,
            'step': self.step_count,
            'binary': mutated_binary,
            'target_func': self.function_name, # è®°å½•å½“å‰ç›®æ ‡å‡½æ•°å
            'loc_valid': loc_valid,
            'no_change': no_change,
            'no_change_streak': self.no_change_streak,
            'invalid_loc_streak': self.invalid_loc_streak,
            'score_delta': score_delta,
        }
        
        # === æ ¸å¿ƒä¿®æ”¹ï¼šæ›´æ–°éš¾åº¦æƒé‡ ===
        if done:
            s_id = self.idx_to_id[self.current_sample_idx]
            final_score = info.get('score', 1.0)
            is_success = 1 if final_score < self.target_score else 0
            
            # 1. æ›´æ–°å†å²è®°å½•
            self.sample_history[s_id].append(is_success)
            
            # 2. åŠ¨æ€æ›´æ–°é‡‡æ ·æƒé‡
            # å¦‚æœå¤±è´¥äº†(0)ï¼Œéš¾åº¦å¢åŠ ï¼Œæƒé‡å¢åŠ 
            # å¦‚æœæˆåŠŸäº†(1)ï¼Œéš¾åº¦é™ä½ï¼Œæƒé‡é™ä½
            # å…¬å¼ï¼šWeight = 1.0 + (1.0 - SuccessRate) * 2.0
            # æœ€éš¾æ ·æœ¬æƒé‡ = 3.0ï¼Œæœ€æ˜“æ ·æœ¬æƒé‡ = 1.0
            
            history = self.sample_history[s_id]
            current_rate = sum(history) / len(history)
            new_weight = 1.0 + (1.0 - current_rate) * 2.0
            
            # æ›´æ–°åˆ°å…¨å±€æƒé‡æ•°ç»„
            self.sample_weights[self.current_sample_idx] = new_weight

            # 3. è®°å½•è¿›æ­¥/åœæ»ï¼ˆç”¨äºè‡ªé€‚åº”åˆ‡æ¢ï¼‰
            best_score = self.sample_best_score.get(s_id)
            if is_success or best_score is None or final_score < (best_score - self.progress_eps):
                self.sample_best_score[s_id] = final_score
                self.sample_no_progress[s_id] = 0
            else:
                self.sample_no_progress[s_id] = self.sample_no_progress.get(s_id, 0) + 1

        
        return state, reward, done, info




    def compute_reward_v2(self, prev_score, current_score, step_count,
                          invalid_loc=False, no_change=False,
                          no_change_streak=0, invalid_streak=0):
        """è®¡ç®—å¥–åŠ±"""
        # åŸºç¡€å¥–åŠ±
        total_reward = 0.0
        # === 1. åŸºç¡€è¿›æ­¥å¥–åŠ± ===
        diff = prev_score - current_score
       
        if diff > self.progress_reward_eps:  # æ˜¾è‘—è¿›æ­¥
            # å›ºå®šæƒé‡ï¼šç®€åŒ–å¥–åŠ±ï¼Œé¿å…åˆ†æ®µé‡å¤æ”¾å¤§
            incremental = diff * self.incremental_scale
            # é¢å¤–é™å¹…å¥–åŠ±ï¼šæŒ‰â€œç›¸å¯¹é™å¹…â€ç»™ bonusï¼Œä¿è¯é™å¾—è¶Šå¤šå¥–åŠ±è¶Šå¤š
            rel_drop = diff / max(prev_score, 1e-6)
            drop_bonus = min(self.drop_bonus_cap, rel_drop * self.drop_bonus_scale)
            total_reward += drop_bonus
            total_reward += self.effective_mutation_bonus
        elif diff < -self.progress_reward_eps:  # æ˜¾è‘—é€€æ­¥
            # å¯¹ç§°å¤„ç†ï¼Œé¿å…è¿‡åº¦æƒ©ç½šå¯¼è‡´æ¢ç´¢å—é™
            incremental = diff * self.incremental_scale
        else:
            # å˜åŒ–å¹…åº¦åœ¨å™ªå£°å¸¦å†…ï¼Œå½“ä½œæ— è¿›å±•å¤„ç†ï¼Œé¿å…å­¦åˆ°â€œæŠ–åŠ¨æŠ•æœºâ€ã€‚
            incremental = 0.0
            no_change = True

        # å…³é”®å†³ç­–ï¼šéš¾åº¦å·²ç»ç”¨äºâ€œé‡‡æ ·æ›´é¢‘ç¹â€ï¼Œè¿™é‡Œä¸å†äºŒæ¬¡æ”¾å¤§å¥–åŠ±ï¼Œ
        # é¿å…å¯¹â€œéš¾æ ·æœ¬â€é‡å¤åŠ æˆå¯¼è‡´è®­ç»ƒä¸ç¨³å®šã€‚
        total_reward += incremental * self.reward_weights['incremental']

        # === 2. ç»ˆææˆåŠŸå¥–åŠ± ===
        if current_score < self.target_score:
            # åŸºç¡€ 10 + è´¨é‡åŠ æˆ + æ•ˆç‡åŠ æˆ
            base_reward = self.ultimate_base_reward
            quality_bonus = (self.target_score - current_score) * self.ultimate_quality_scale
            efficiency_bonus = max(0, (self.max_steps - step_count) * self.ultimate_efficiency_scale)      # max_step - step_count
            
            ultimate = base_reward + quality_bonus + efficiency_bonus

            total_reward += ultimate * self.reward_weights['ultimate']

        # === 3. æ˜¾å¼æƒ©ç½šï¼ˆåˆ†æ®µå¼ï¼‰===
        penalty = 0.0
        step_ratio = step_count / max(float(self.max_steps), 1.0)
        if step_ratio < 0.33:
            time_penalty = self.time_penalty_schedule[0]
        elif step_ratio < 0.66:
            time_penalty = self.time_penalty_schedule[1]
        else:
            time_penalty = self.time_penalty_schedule[2]

        if no_change:
            s = max(int(no_change_streak), 1)
            if s <= 1:
                factor = self.no_change_penalty_factors[0]
            elif s <= 3:
                factor = self.no_change_penalty_factors[1]
            elif s <= 6:
                factor = self.no_change_penalty_factors[2]
            else:
                factor = self.no_change_penalty_factors[3]
            penalty += self.no_change_penalty * factor

        if invalid_loc:
            s = max(int(invalid_streak), 1)
            if s <= 1:
                factor = self.invalid_loc_penalty_factors[0]
            elif s <= 3:
                factor = self.invalid_loc_penalty_factors[1]
            else:
                factor = self.invalid_loc_penalty_factors[2]
            penalty += self.invalid_loc_penalty * factor

        penalty += time_penalty
        penalty = min(penalty, self.penalty_cap)


        total_reward -= penalty * self.reward_weights['penalty']
        
        # === 5. ç¡¬è£å‰ªï¼ˆä¸æ˜¯å½’ä¸€åŒ–ï¼ï¼‰===
        # åªæ˜¯é˜²æ­¢æç«¯å€¼ï¼Œä¸æ”¹å˜å¥–åŠ±çš„ç›¸å¯¹å¤§å°å…³ç³»
        clipped = float(np.clip(total_reward, -50.0, 100.0))
        self._record_reward_clip(total_reward, clipped)
        return clipped

    def _record_reward_clip(self, raw_reward, clipped_reward):
        self._reward_clip_total += 1
        if raw_reward > 80.0:
            self._reward_clip_hi += 1
        elif raw_reward < -40.0:
            self._reward_clip_lo += 1

        if self.reward_clip_log_interval > 0 and self._reward_clip_total % self.reward_clip_log_interval == 0:
            total = self._reward_clip_total
            hi_ratio = self._reward_clip_hi / total
            lo_ratio = self._reward_clip_lo / total
            logger.info(
                f"[reward_clip] total={total} hi={self._reward_clip_hi} ({hi_ratio:.1%}) "
                f"lo={self._reward_clip_lo} ({lo_ratio:.1%})"
            )

    def _refresh_current_difficulty(self):
        if self.current_sample_data is None:
            self.current_difficulty = 0.5
            return
        s_id = self.idx_to_id[self.current_sample_idx]
        history = self.sample_history.get(s_id, [])
        if len(history) > 0:
            success_rate = sum(history) / len(history)
            self.current_difficulty = 1.0 - success_rate
            self.current_difficulty = max(0.1, self.current_difficulty)
        else:
            self.current_difficulty = 0.5

    def _adaptive_hold_limit(self):
        if not self.adaptive_hold:
            return max(1, int(self.sample_hold_interval))
        hold = int(round(self.hold_min + self.current_difficulty * (self.hold_max - self.hold_min)))
        return max(self.hold_min, min(self.hold_max, hold))

    def _switch_next_target(self):
        """
        [è¾…åŠ©å‡½æ•°] æ ¹æ®éš¾åº¦æƒé‡é‡‡æ ·ä¸‹ä¸€ä¸ªç›®æ ‡
        """
        # æƒé‡å½’ä¸€åŒ–æˆæ¦‚ç‡
        probs = self.sample_weights / np.sum(self.sample_weights)
        # æŒ‰æ¦‚ç‡æŠ½å–ç´¢å¼•
        self.current_sample_idx = np.random.choice(len(self.dataset), p=probs)
        self.current_sample_data = self.dataset[self.current_sample_idx]

        self.episodes_on_current = 0
        # Reset cached function address when switching targets.
        self.original_func_addr = None

        # è®¡ç®—å½“å‰éš¾åº¦ (1.0 - æˆåŠŸç‡)
        self._refresh_current_difficulty()
        self.current_hold_limit = self._adaptive_hold_limit()

        self.original_binary = self.current_sample_data['binary_path']
        self.function_name = self.current_sample_data['func_name']

    def reset(self, force_switch=False):
        """
        é‡ç½®ç¯å¢ƒï¼šå®ç°è‡ªåŠ¨åˆ‡æ¢ç›®æ ‡ (Hold-N Strategy)
        
        å‚æ•°:
            force_switch: å¦‚æœä¸º Trueï¼Œå¼ºåˆ¶åˆ‡æ¢ç›®æ ‡ï¼ˆç”¨äºé”™è¯¯æ¢å¤ï¼‰
        """
        # å¼ºåˆ¶åˆ‡æ¢ï¼ˆé”™è¯¯æ¢å¤ï¼‰ï¼šå¿½ç•¥ Hold-N ç­–ç•¥ï¼Œç›´æ¥åˆ‡æ¢ç›®æ ‡
        if force_switch:
            self._switch_next_target()
            logger.warning(f"ğŸ”„ FORCE SWITCH (Error Recovery) -> {os.path.basename(self.original_binary)}::{self.function_name}")
            logger.warning(f"   Version: {self.current_sample_data.get('version')} | Opt: {self.current_sample_data.get('opt_level')}")
        # æ­£å¸¸åˆ‡æ¢ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢ç›®æ ‡
        elif self.current_sample_data is None:
            self._switch_next_target()
            logger.success(f"ğŸ”„ SWITCH TARGET -> {os.path.basename(self.original_binary)}::{self.function_name}")
            logger.success(f"   Version: {self.current_sample_data.get('version')} | Opt: {self.current_sample_data.get('opt_level')}")
        else:
            # æ›´æ–°å½“å‰éš¾åº¦ä¸è‡ªé€‚åº” hold é™åˆ¶
            self._refresh_current_difficulty()
            self.current_hold_limit = self._adaptive_hold_limit()
            s_id = self.idx_to_id[self.current_sample_idx]
            stall_count = self.sample_no_progress.get(s_id, 0)
            should_switch = (
                self.episodes_on_current >= self.current_hold_limit or
                stall_count >= self.stall_limit
            )
            if should_switch:
                self._switch_next_target()
                reason = "stall" if stall_count >= self.stall_limit else "hold"
                logger.success(
                    f"ğŸ”„ SWITCH TARGET ({reason}) -> {os.path.basename(self.original_binary)}::{self.function_name} "
                    f"(hold={self.current_hold_limit}, stall={stall_count})"
                )
                logger.success(f"   Version: {self.current_sample_data.get('version')} | Opt: {self.current_sample_data.get('opt_level')}")
            else:
                # ä¿æŒå½“å‰ç›®æ ‡ï¼Œå¢åŠ è®¡æ•°
                self.episodes_on_current += 1
                logger.info(
                    f"ğŸ”„ KEEP TARGET ({self.episodes_on_current}/{self.current_hold_limit}) -> {self.function_name} "
                    f"(stall={stall_count})"
                )

        # é‡ç½®ç¯å¢ƒçŠ¶æ€
        self.current_binary = self.original_binary
        self.mutation_history = []
        self.step_count = 0
        self.no_change_streak = 0
        self.invalid_loc_streak = 0
        
        # æå–åˆå§‹ç‰¹å¾
        state = self.extract_features(self.original_binary)
        return state

    def get_loc_mask(self, n_locs=3):
        """
        è¿”å›ä½ç½®æ©ç ï¼ˆé•¿åº¦ä¸º n_locsï¼‰ã€‚
        1 è¡¨ç¤ºè¯¥ä½ç½®å¯ç”¨ï¼ˆæœ‰å¯¹åº”å…³é”®å—ï¼‰ï¼Œ0 è¡¨ç¤ºä¸å¯ç”¨ã€‚
        è‹¥å½“å‰å…³é”®å—ä¸ºç©ºï¼Œè¿”å›å…¨ 1ï¼ˆä¸åšç¡¬å±è”½ï¼Œé¿å…å…¨é›¶å¯¼è‡´æ— æ³•é‡‡æ ·ï¼‰ã€‚
        """
        try:
            n_locs = int(n_locs)
        except Exception:
            n_locs = 3
        if n_locs <= 0:
            return []
        if not self.current_critical_blocks:
            return [1] * n_locs
        valid = min(len(self.current_critical_blocks), n_locs)
        return [1] * valid + [0] * (n_locs - valid)
    
    def clear_acfg_cache(self):
        """
        æ¸…ç† ACFG ç‰¹å¾ç¼“å­˜
        
        ç”¨äºé‡Šæ”¾å†…å­˜ï¼Œé€šå¸¸åœ¨åˆ‡æ¢å¤§é‡ä¸åŒç›®æ ‡æ—¶è°ƒç”¨
        """
        logger.info("ACFG ç¼“å­˜å·²ç¦ç”¨ï¼Œæ— éœ€æ¸…ç†")
    
    def get_cache_stats(self):
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            dict: åŒ…å«å‘½ä¸­ç‡ã€å‘½ä¸­æ•°ã€æœªå‘½ä¸­æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            'cache_size': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'hit_rate': 0.0
        }

if __name__ == '__main__':
    bin_path = '/home/ycy/ours/Deceiving-DNN-based-Binary-Matching/rl_framework/datasets/coreutils/bin/coreutils-8.15-O0/sort'
    DATASET_PATH = '/home/ycy/ours/Deceiving-DNN-based-Binary-Matching/rl_framework/utils/dataset_test.json'
    env = BinaryPerturbationEnv(save_path="/tmp/test_env", dataset_path=DATASET_PATH)
    state = env.extract_features_from_function(bin_path,'xstrtoumax')
    # print(len(state))
