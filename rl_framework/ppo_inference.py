#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PPO Inference Script - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡ŒäºŒè¿›åˆ¶ä»£ç å˜å¼‚
"""

import os
import sys
import glob
import shutil
import json
import numpy as np
import torch
import argparse
from loguru import logger

# å¯¼å…¥ç¯å¢ƒå’Œ Agent
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from env_wrapper import BinaryPerturbationEnv
from ppo_agent import PPOAgent


def cleanup_inference_files(save_path, keep_binary):
    """
    æ¸…ç†æ¨ç†ä¸­é—´æ–‡ä»¶ï¼Œä»…ä¿ç•™æœ€ä½³ç»“æœ
    
    ä¿ç•™: inference_log.txt, æœ€ä½³å˜å¼‚ç»“æœç›®å½•
    åˆ é™¤: æ‰€æœ‰å…¶ä»– *_container ç›®å½•å’Œä¸´æ—¶æ–‡ä»¶
    """
    if not os.path.exists(save_path) or not keep_binary:
        return
    
    keep_path = os.path.abspath(keep_binary)
    keep_container = None
    
    # æ‰¾åˆ°éœ€è¦ä¿ç•™çš„containerç›®å½•
    if '_container' in keep_path:
        # keep_path å¯èƒ½æ˜¯ /path/xxx_container/xxx æˆ– /path/xxx_container
        parts = keep_path.split('_container')
        if parts:
            keep_container = parts[0] + '_container'
    
    deleted = 0
    freed = 0
    
    # æ¸…ç†æ‰€æœ‰containerç›®å½•ï¼ˆé™¤äº†éœ€è¦ä¿ç•™çš„ï¼‰
    for container in glob.glob(os.path.join(save_path, '*_container')):
        container_abs = os.path.abspath(container)
        
        # ä¿ç•™æœ€ä½³ç»“æœæ‰€åœ¨çš„container
        if keep_container and container_abs == keep_container:
            continue
        
        try:
            size = sum(os.path.getsize(os.path.join(d, f)) 
                      for d, _, files in os.walk(container) for f in files)
            shutil.rmtree(container)
            deleted += 1
            freed += size
        except Exception as e:
            logger.warning(f"æ— æ³•åˆ é™¤ {os.path.basename(container)}: {e}")
    
    # æ¸…ç†å…¶ä»–ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™ inference_log.txtï¼‰
    for item in os.listdir(save_path):
        if item == 'inference_log.txt':
            continue
        
        path = os.path.join(save_path, item)
        if os.path.isfile(path):
            try:
                freed += os.path.getsize(path)
                os.remove(path)
                deleted += 1
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ é™¤ {item}: {e}")
    
    # æ¸…ç† rl_output ä¸­çš„ä¸­é—´æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨ save_path ä¸‹çš„ç§æœ‰ç›®å½•ï¼‰
    rl_output = os.path.join(save_path, 'rl_output')
    if not os.path.exists(rl_output):
        rl_output = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'rl_output')
    if os.path.exists(rl_output):
        for mutant in glob.glob(os.path.join(rl_output, 'mutant_*.bin*')):
            try:
                freed += os.path.getsize(mutant)
                os.remove(mutant)
                deleted += 1
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ é™¤ {os.path.basename(mutant)}: {e}")
    
    if deleted > 0:
        size_mb = freed / (1024 * 1024)
        logger.success(f"âœ“ æ¸…ç†å®Œæˆ: åˆ é™¤ {deleted} é¡¹ï¼Œé‡Šæ”¾ {size_mb:.2f} MB")
    
    if keep_container:
        logger.info(f"âœ“ å·²ä¿ç•™æœ€ä½³ç»“æœ: {os.path.basename(keep_container)}")


def inference_ppo(args):
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„ PPO æ¨¡å‹è¿›è¡Œæ¨ç†
    
    å‚æ•°:
        args: å‘½ä»¤è¡Œå‚æ•°
            - model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
            - binary: åŸå§‹äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„
            - function: ç›®æ ‡å‡½æ•°å
            - save_path: å˜å¼‚ç»“æœä¿å­˜è·¯å¾„
            - max_steps: æœ€å¤§æ­¥æ•°ï¼ˆé»˜è®¤30ï¼‰
            - target_score: ç›®æ ‡åˆ†æ•°ï¼ˆé»˜è®¤0.40ï¼‰
    """
    logger.info("=" * 80)
    logger.info("PPO æ¨ç†æ¨¡å¼")
    logger.info("=" * 80)
    logger.info(f"æ¨¡å‹è·¯å¾„: {args.model_path}")
    logger.info(f"åŸå§‹äºŒè¿›åˆ¶: {args.binary}")
    logger.info(f"ç›®æ ‡å‡½æ•°: {args.function}")
    logger.info(f"ä¿å­˜è·¯å¾„: {args.save_path}")
    logger.info(f"æœ€å¤§æ­¥æ•°: {args.max_steps}")
    logger.info(f"ç›®æ ‡åˆ†æ•°: {args.target_score}")
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model_path):
        logger.error(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model_path}")
        return
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(args.save_path, exist_ok=True)
    
    # åˆå§‹åŒ–ç¯å¢ƒ
    logger.info("åˆå§‹åŒ–å˜å¼‚ç¯å¢ƒ...")
    dataset_path = os.path.join(args.save_path, "inference_dataset.json")
    dataset = [{
        "binary_path": os.path.abspath(args.binary),
        "binary_name": os.path.basename(args.binary),
        "version": "inference",
        "opt_level": "unknown",
        "func_name": args.function,
        "func_addr": 0,
        "size": 0,
        "id": "inference"
    }]
    with open(dataset_path, "w") as f:
        json.dump(dataset, f, indent=2)

    env = BinaryPerturbationEnv(
        save_path=args.save_path,
        dataset_path=dataset_path,
        sample_hold_interval=1,
        max_steps=args.max_steps
    )
    env.set_state_dim(args.state_dim)
    logger.info("ç¯å¢ƒåˆå§‹åŒ–å®Œæˆ âœ“")
    
    # åˆå§‹åŒ– PPO Agent å¹¶åŠ è½½æ¨¡å‹
    logger.info("åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    device = 'cuda' if torch.cuda.is_available() and args.use_gpu else 'cpu'
    agent = PPOAgent(
        state_dim=args.state_dim,
        n_actions=7,
        device=device
    )
    agent.load(args.model_path)
    agent.policy.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆ âœ“ (è®¾å¤‡: {device})")
    
    # æ‰§è¡Œæ¨ç†
    logger.info("=" * 80)
    logger.info("å¼€å§‹å˜å¼‚è¿‡ç¨‹")
    logger.info("=" * 80)
    
    state = env.reset()
    success = False
    best_score = float('inf')
    best_binary = None
    
    # è®°å½•æ¯æ­¥ä¿¡æ¯
    step_records = []
    
    for step in range(args.max_steps):
        logger.info(f"\næ­¥éª¤ {step + 1}/{args.max_steps}")
        logger.info("-" * 60)
        
        # ä½¿ç”¨æ¨¡å‹é€‰æ‹©åŠ¨ä½œï¼ˆä¸æ¢ç´¢ï¼Œé€‰æ‹©æœ€ä¼˜åŠ¨ä½œï¼‰
        joint_idx, loc_idx, act_idx, actual_action, log_prob, value = agent.select_action(state, explore=False)

        logger.info(f"é€‰æ‹©åŠ¨ä½œ: {actual_action} (ä½ç½®: {loc_idx}, åŠ¨ä½œç´¢å¼•: {act_idx}, è”åˆç´¢å¼•: {joint_idx})")
        logger.info(f"çŠ¶æ€ä»·å€¼: {value:.4f}")
        
        # æ‰§è¡ŒåŠ¨ä½œ
        next_state, reward, done, info = env.step(actual_action, loc_idx)
        
        # è®°å½•ä¿¡æ¯
        step_info = {
            'step': step + 1,
            'loc': loc_idx,
            'act_idx': act_idx,
            'action': actual_action,
            'score': info.get('score', 1.0),
            'grad': info.get('grad', 0.0),
            'binary': info.get('binary', None),
            'reward': reward,
            'value': value
        }
        step_records.append(step_info)
        
        # è¾“å‡ºç»“æœ
        if 'score' in info:
            logger.info(f"ç›¸ä¼¼åº¦åˆ†æ•°: {info['score']:.4f}")
            logger.info(f"æ¢¯åº¦å€¼: {info.get('grad', 0):.4f}")
            logger.info(f"å¥–åŠ±: {reward:.4f}")
            
            # æ›´æ–°æœ€ä½³ç»“æœ
            if info['score'] < best_score:
                best_score = info['score']
                best_binary = info.get('binary', None)
                logger.success(f"âœ¨ å‘ç°æ›´å¥½çš„ç»“æœ! åˆ†æ•°: {best_score:.4f}")
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°ç›®æ ‡
            if info['score'] < args.target_score:
                success = True
                logger.success(f"ğŸ‰ æˆåŠŸè¾¾åˆ°ç›®æ ‡! åˆ†æ•°: {info['score']:.4f} < {args.target_score}")
                logger.success(f"å˜å¼‚åçš„äºŒè¿›åˆ¶: {info.get('binary', 'unknown')}")
                break
        else:
            logger.warning("æœªèƒ½è·å–è¯„ä¼°åˆ†æ•°")
        
        state = next_state
        
        if done:
            logger.info("å›åˆç»“æŸ")
            break
    
    # è¾“å‡ºæ€»ç»“
    logger.info("")
    logger.info("=" * 80)
    logger.info("æ¨ç†å®Œæˆ")
    logger.info("=" * 80)
    logger.info(f"æ‰§è¡Œæ­¥æ•°: {step + 1}")
    logger.info(f"æœ€ä½³åˆ†æ•°: {best_score:.4f}")
    
    if success:
        logger.success(f"âœ“ æˆåŠŸè¾¾åˆ°ç›®æ ‡ (åˆ†æ•° < {args.target_score})")
    else:
        logger.warning(f"âœ— æœªè¾¾åˆ°ç›®æ ‡ (åˆ†æ•° >= {args.target_score})")
    
    if best_binary:
        logger.info(f"æœ€ä½³å˜å¼‚ç»“æœ: {best_binary}")
    
    # ä¿å­˜æ¨ç†æ—¥å¿—
    log_file = os.path.join(args.save_path, 'inference_log.txt')
    with open(log_file, 'w') as f:
        f.write(f"æ¨¡å‹: {args.model_path}\n")
        f.write(f"äºŒè¿›åˆ¶: {args.binary}\n")
        f.write(f"å‡½æ•°: {args.function}\n")
        f.write(f"æœ€ä½³åˆ†æ•°: {best_score:.4f}\n")
        f.write(f"æˆåŠŸ: {success}\n")
        f.write(f"æœ€ä½³ç»“æœ: {best_binary}\n\n")
        f.write("æ­¥éª¤è¯¦æƒ…:\n")
        f.write("step,loc,act_idx,action,score,grad,reward,value,binary\n")
        for record in step_records:
            f.write(f"{record['step']},{record['loc']},{record['act_idx']},{record['action']},{record['score']:.4f},"
                   f"{record['grad']:.4f},{record['reward']:.4f},{record['value']:.4f},"
                   f"{record['binary']}\n")
    
    logger.info(f"æ¨ç†æ—¥å¿—å·²ä¿å­˜: {log_file}")
    
    # æ¸…ç†ä¸­é—´æ–‡ä»¶ï¼Œåªä¿ç•™æœ€ä½³ç»“æœ
    logger.info("")
    cleanup_inference_files(args.save_path, best_binary)
    
    return best_score, best_binary, success


def batch_inference(args):
    """
    æ‰¹é‡æ¨ç†ï¼šå¯¹å¤šä¸ªäºŒè¿›åˆ¶æ–‡ä»¶æˆ–å‡½æ•°è¿›è¡Œå˜å¼‚
    """
    logger.info("æ‰¹é‡æ¨ç†æ¨¡å¼")
    
    # è¯»å–æ‰¹é‡é…ç½®æ–‡ä»¶
    if not os.path.exists(args.batch_file):
        logger.error(f"æ‰¹é‡é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {args.batch_file}")
        return
    
    with open(args.batch_file, 'r') as f:
        lines = f.readlines()
    
    results = []
    
    for idx, line in enumerate(lines):
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        
        parts = line.split(',')
        if len(parts) < 2:
            logger.warning(f"è·³è¿‡æ— æ•ˆè¡Œ: {line}")
            continue
        
        binary, function = parts[0], parts[1]
        save_path = parts[2] if len(parts) > 2 else f"{args.save_path}_{idx}"
        
        logger.info("")
        logger.info("=" * 80)
        logger.info(f"æ‰¹é‡ä»»åŠ¡ {idx + 1}/{len(lines)}")
        logger.info("=" * 80)
        
        # è®¾ç½®å‚æ•°
        args.binary = binary
        args.function = function
        args.save_path = save_path
        
        # æ‰§è¡Œæ¨ç†
        try:
            best_score, best_binary, success = inference_ppo(args)
            results.append({
                'binary': binary,
                'function': function,
                'score': best_score,
                'success': success,
                'output': best_binary
            })
        except Exception as e:
            logger.error(f"ä»»åŠ¡å¤±è´¥: {e}")
            results.append({
                'binary': binary,
                'function': function,
                'score': float('inf'),
                'success': False,
                'output': None
            })
    
    # è¾“å‡ºæ‰¹é‡ç»“æœ
    logger.info("")
    logger.info("=" * 80)
    logger.info("æ‰¹é‡æ¨ç†å®Œæˆ")
    logger.info("=" * 80)
    
    success_count = sum(1 for r in results if r['success'])
    logger.info(f"æ€»ä»»åŠ¡æ•°: {len(results)}")
    logger.info(f"æˆåŠŸæ•°: {success_count}")
    logger.info(f"æˆåŠŸç‡: {success_count / len(results) * 100:.2f}%")
    
    # ä¿å­˜æ‰¹é‡ç»“æœ
    batch_log = os.path.join(os.path.dirname(args.batch_file), 'batch_inference_results.txt')
    with open(batch_log, 'w') as f:
        f.write("binary,function,score,success,output\n")
        for r in results:
            f.write(f"{r['binary']},{r['function']},{r['score']:.4f},"
                   f"{r['success']},{r['output']}\n")
    
    logger.info(f"æ‰¹é‡ç»“æœå·²ä¿å­˜: {batch_log}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='PPO Inference for Binary Perturbation')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model-path', required=True, help='è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ (å¦‚ rl_models/ppo_model_best.pt)')
    
    # ç›®æ ‡å‚æ•°
    parser.add_argument('--binary', help='åŸå§‹äºŒè¿›åˆ¶æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--function', help='ç›®æ ‡å‡½æ•°å')
    parser.add_argument('--save-path', help='å˜å¼‚ç»“æœä¿å­˜è·¯å¾„')
    
    # æ¨ç†å‚æ•°
    parser.add_argument('--state-dim', type=int, default=256, help='çŠ¶æ€ç»´åº¦ï¼ˆå¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œé»˜è®¤ 256ï¼‰')
    parser.add_argument('--max-steps', type=int, default=30, help='æœ€å¤§æ­¥æ•°')
    parser.add_argument('--target-score', type=float, default=0.40, help='ç›®æ ‡ç›¸ä¼¼åº¦åˆ†æ•°')
    parser.add_argument('--use-gpu', action='store_true', help='ä½¿ç”¨ GPU')
    
    # æ‰¹é‡æ¨¡å¼
    parser.add_argument('--batch', action='store_true', help='æ‰¹é‡æ¨ç†æ¨¡å¼')
    parser.add_argument('--batch-file', help='æ‰¹é‡é…ç½®æ–‡ä»¶ (æ ¼å¼: binary,function,save_path)')
    
    args = parser.parse_args()
    
    # æ‰¹é‡æ¨¡å¼æˆ–å•æ¬¡æ¨ç†
    if args.batch:
        if not args.batch_file:
            logger.error("æ‰¹é‡æ¨¡å¼éœ€è¦æŒ‡å®š --batch-file")
            sys.exit(1)
        batch_inference(args)
    else:
        if not args.binary or not args.function or not args.save_path:
            logger.error("å•æ¬¡æ¨ç†æ¨¡å¼éœ€è¦æŒ‡å®š --binary, --function, --save-path")
            sys.exit(1)
        inference_ppo(args)
